{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Row': 1,\n",
       "  'NERR Site ID ': 'ace                                               ',\n",
       "  'Station Code': 'acebbnut  ',\n",
       "  'Station Name': 'Big Bay                                 ',\n",
       "  'Lat Long': \"32° 29' 38.76 N - 80° 19' 26.76 W\",\n",
       "  'Latitude ': 32.4941,\n",
       "  ' Longitude': 80.3241,\n",
       "  ' Status': 'Inactive  ',\n",
       "  ' Active Dates': 'Feb 2002-Dec 2014',\n",
       "  ' State': 'sc        ',\n",
       "  ' Reserve Name': 'Ashepoo Combahee Edisto Basin                     ',\n",
       "  'Real Time': nan,\n",
       "  'HADS ID': nan,\n",
       "  'GMT Offset': -5,\n",
       "  'Station Type': 2,\n",
       "  'Region': 2,\n",
       "  'isSWMP': 'P',\n",
       "  'Parameters Reported': 'PO4F,NH4F,NO23F,CHLA_N,DIN,NO2F,NO3F'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_clipboard().to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions, StandardOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parsing functions...\n",
    "def flag_parse(val):\n",
    "    # Remove brackets from flag columns...\n",
    "    if val:\n",
    "        val = val.strip()\n",
    "        regex = r\"<?(-?\\d+)>?\\D?\"\n",
    "        parsed_val = re.findall(regex, val)[0]\n",
    "        return float(parsed_val) if parsed_val else None\n",
    "    else:\n",
    "        return None\n",
    "def measurement_parse(val):\n",
    "    val = val.strip()\n",
    "    return float(val) if val else None \n",
    "def date_parse(val):\n",
    "    val = val.strip()\n",
    "    return parse(val) if val else None\n",
    "def integer_parse(val):\n",
    "    val = val.strip()\n",
    "    return int(val) if val else None\n",
    "def string_parse(val):\n",
    "    val = val.strip()\n",
    "    return str(val) if val else None\n",
    "\n",
    "class DataIngestions:\n",
    "    \n",
    "    # Dataset names\n",
    "    WQ = \"wq\"\n",
    "    MET = \"met\"\n",
    "    NUT = \"nut\"\n",
    "    STATION = \"station\"\n",
    "    ENV_BUCKET = \"environmental_data\"\n",
    "    LANDING_ZONE = \"landing_zone\"\n",
    "   \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def read_csv(self, string_input):\n",
    "        for line in csv.reader([string_input], quotechar='\"', delimiter=',', quoting=csv.QUOTE_ALL, skipinitialspace=True):\n",
    "            if line:\n",
    "                # Strip trailing spaces                \n",
    "                line = [field.strip() for field in line]\n",
    "                return line\n",
    "        \n",
    "    def parse_wq_row(self,  row):\n",
    "        if row:\n",
    "            return beam.Row(\n",
    "                StationCode = string_parse(row[0]),\n",
    "                isSWMP = string_parse(row[1]),\n",
    "                DateTimeStamp = date_parse(row[2]),\n",
    "                Historical = integer_parse(row[3]),\n",
    "                ProvisionalPlus = integer_parse(row[4]),\n",
    "                F_Record = flag_parse(row[5]),\n",
    "                Temp = measurement_parse(row[6]),\n",
    "                F_Temp = flag_parse(row[7]),\n",
    "                SpCond = measurement_parse(row[8]),\n",
    "                F_SpCond = flag_parse(row[9]),\n",
    "                Sal = measurement_parse(row[10]),\n",
    "                F_Sal = flag_parse(row[11]),\n",
    "                DO_Pct = measurement_parse(row[12]),\n",
    "                F_DO_Pct = flag_parse(row[13]),\n",
    "                DO_mgl = measurement_parse(row[14]),\n",
    "                F_DO_mgl = flag_parse(row[15]),\n",
    "                Depth = measurement_parse(row[16]),\n",
    "                F_Depth = flag_parse(row[17]),\n",
    "                cDepth = measurement_parse(row[18]),\n",
    "                F_cDepth = flag_parse(row[19]),\n",
    "                Level = measurement_parse(row[20]),\n",
    "                F_Level = flag_parse(row[21]),\n",
    "                cLevel = measurement_parse(row[22]),\n",
    "                F_cLevel = flag_parse(row[23]),\n",
    "                pH = measurement_parse(row[24]),\n",
    "                F_pH = flag_parse(row[25]),\n",
    "                Turb = measurement_parse(row[26]),\n",
    "                F_Turb = flag_parse(row[27]),\n",
    "                ChlFluor = measurement_parse(row[28]),\n",
    "                F_ChlFluor = flag_parse(row[29])                    \n",
    "            )\n",
    "\n",
    "    def parse_nut_row(self,  row):\n",
    "        if row:\n",
    "            return beam.Row(\n",
    "                StationCode = string_parse(row[\"StationCode\"]),\n",
    "                isSWMP = string_parse(row[\"isSWMP\"]),\n",
    "                DateTimeStamp = date_parse(row[\"DateTimeStamp\"]),\n",
    "                Historical = integer_parse(row[\"Historical\"]),\n",
    "                ProvisionalPlus = integer_parse(row[\"ProvisionalPlus\"]),\n",
    "                CollMethd = integer_parse(row[\"CollMethd\"]),\n",
    "                REP = string_parse(row[\"REP\"]),\n",
    "                F_Record = flag_parse(row[\"F_Record\"]),\n",
    "                PO4F = measurement_parse(row[\"PO4F\"]),\n",
    "                F_PO4F = flag_parse(row[\"F_PO4F\"]),\n",
    "                NH4F = measurement_parse(row[\"NH4F\"]),\n",
    "                F_NH4F = flag_parse(row[\"F_NH4F\"]),\n",
    "                NO2F = measurement_parse(row[\"NO2F\"]),\n",
    "                F_NO2F = flag_parse(row[\"F_NO2F\"]),\n",
    "                NO3F = measurement_parse(row[\"NO3F\"]),\n",
    "                F_NO3F = flag_parse(row[\"F_NO3F\"]),\n",
    "                NO23F = measurement_parse(row[\"NO23F\"]),\n",
    "                F_NO23F = flag_parse(row[\"F_NO23F\"]),\n",
    "                CHLA_N = measurement_parse(row[\"CHLA_N\"]),\n",
    "                F_CHLA_N = flag_parse(row[\"F_CHLA_N\"])                   \n",
    "            )        \n",
    "\n",
    "    def parse_met_row(self,  row):\n",
    "        if row:\n",
    "            return beam.Row(\n",
    "                StationCode = string_parse(row[0]),\n",
    "                isSWMP = string_parse(row[1]),\n",
    "                DateTimeStamp = date_parse(row[2]),\n",
    "                Historical = integer_parse(row[3]),\n",
    "                ProvisionalPlus = integer_parse(row[4]),\n",
    "                Frequency = integer_parse(row[5]),\n",
    "                F_Record = flag_parse(row[6]),\n",
    "                ATemp = measurement_parse(row[7]),\n",
    "                F_ATemp = flag_parse(row[8]),\n",
    "                RH = measurement_parse(row[9]),\n",
    "                F_RH = flag_parse(row[10]),\n",
    "                BP = measurement_parse(row[11]),\n",
    "                F_BP = flag_parse(row[12]),\n",
    "                WSpd = measurement_parse(row[13]),\n",
    "                F_WSpd = flag_parse(row[14]),\n",
    "                MaxWSpd = measurement_parse(row[15]),\n",
    "                F_MaxWSpd = flag_parse(row[16]),\n",
    "                MaxWSpdT = string_parse(row[17]),\n",
    "                Wdir = measurement_parse(row[18]),\n",
    "                F_Wdir = flag_parse(row[19]),\n",
    "                SDWDir = measurement_parse(row[20]),\n",
    "                F_SDWDir = flag_parse(row[21]),\n",
    "                TotPAR = measurement_parse(row[22]),\n",
    "                F_TotPAR = flag_parse(row[23]),\n",
    "                TotPrcp = measurement_parse(row[24]),\n",
    "                F_TotPrcp = flag_parse(row[25]),\n",
    "                TotSoRad = string_parse(row[26]),\n",
    "                F_TotSoRad = flag_parse(row[27])\n",
    "            )\n",
    "\n",
    "    def parse_station_row(self,  row):\n",
    "        if row:\n",
    "            return beam.Row(\n",
    "                # Index 1 is just row num\n",
    "                NERRSiteID = string_parse(row[1]),\n",
    "                StationCode = string_parse(row[2]),\n",
    "                StationName = string_parse(row[3]),\n",
    "                LatLong = string_parse(row[4]),\n",
    "                Latitude = measurement_parse(row[5]),\n",
    "                Longitude = measurement_parse(row[6]),\n",
    "                Status = string_parse(row[7]),\n",
    "                ActiveDates = string_parse(row[8]),\n",
    "                State = string_parse(row[9]),\n",
    "                ReserveName = string_parse(row[10]),\n",
    "                RealTime = string_parse(row[11]),\n",
    "                HADSID = string_parse(row[12]),\n",
    "                GMTOffset = measurement_parse(row[13]),\n",
    "                StationType = integer_parse(row[14]),\n",
    "                Region = integer_parse(row[15]),\n",
    "                isSWMP = string_parse(row[16]),\n",
    "                ParametersReported = string_parse(row[17])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.cloud import storage\n",
    "# https://googleapis.dev/python/storage/latest/blobs.html\n",
    "\n",
    "from collections import namedtuple\n",
    "import csv\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import ReadFromText, ReadAllFromText\n",
    "from apache_beam.io import WriteToText\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.io import fileio\n",
    "from apache_beam.dataframe.convert import to_dataframe\n",
    "from apache_beam.dataframe.convert import to_pcollection\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "import io\n",
    "import re\n",
    "\n",
    "    \n",
    "di = DataIngestions()\n",
    "\n",
    "# https://beam.apache.org/documentation/dsls/dataframes/overview/\n",
    "def run(argv=None, save_main_session=True):\n",
    "\n",
    "#     datasets = di.get_dataset_paths()\n",
    "    # https://docs.google.com/presentation/d/10XnYgKsTzuvXuQrdt9KtA21l2ifXstWMw19r6_wWpJ0/edit#slide=id.g90d6944d57_0_1281\n",
    "\n",
    "    options = PipelineOptions()\n",
    "    google_cloud_options = options.view_as(GoogleCloudOptions)\n",
    "    google_cloud_options.project = 'data-science'\n",
    "    google_cloud_options.job_name = 'nerr-pipeline'\n",
    "    google_cloud_options.staging_location = 'gs://environmental_data/'\n",
    "    google_cloud_options.temp_location = 'gs://environmental_data/' \n",
    "    google_cloud_options.region = 'us-east1'        \n",
    "    google_cloud_options.service_account_email = \"pipeline-admin-sc@data-science-306122.iam.gserviceaccount.com\"\n",
    "    options.view_as(StandardOptions).runner = 'DataflowRunner'    \n",
    "    \n",
    "    with beam.Pipeline(options=PipelineOptions()) as p:\n",
    "        print(options)\n",
    "        # Creates a PCollection of files\n",
    "\n",
    "#         wq_collection = (\n",
    "#             p\n",
    "#             | \"WQ Dataset\" >> beam.Create(datasets.get(di.WQ)[0:1])\n",
    "#             | \"Read WQ CSV files\" >> ReadAllFromText(skip_header_lines=1)\n",
    "#             | \"Split WQ CSV files\" >> beam.Map(di.read_csv)\n",
    "#             | \"WQ Parse and To Row\" >> beam.Map(\n",
    "#                 lambda row: di.parse_wq_row(row)\n",
    "#             )\n",
    "# #             | \"Print WQ\" >> beam.Map(print)            \n",
    "#         )\n",
    "        wq_collection = (\n",
    "            p\n",
    "#             | \"WQ Dataset\" >> beam.Create(datasets.get(di.WQ)[0:1])\n",
    "            | 'MatchAll' >> beam.io.ReadFromText(\"gs://environmental_data/landing_zone/cdmo/advanced_query_system/2021_02_28/*nut*.csv\")\n",
    "#             | beam.Reshuffle()\n",
    "#             | 'ReadEach' >> fileio.ReadMatches()\n",
    "#             | beam.FlatMap(lambda rfile:\n",
    "#                            csv.DictReader(io.TextIOWrapper(rfile.open()))\n",
    "#             )\n",
    "            | \"Print WQ\" >> beam.Map(print)            \n",
    "        )            \n",
    "\n",
    "        \n",
    "#         nut_collection = (\n",
    "#             p\n",
    "#             | \"NUT Dataset\" >> beam.Create(datasets.get(di.NUT)[0:1])\n",
    "#             | \"Read NUT CSV files\" >> ReadAllFromText(skip_header_lines=1)\n",
    "#             | \"Split NUT CSV files\" >> beam.Map(di.read_csv)\n",
    "#             | \"NUT Parse and To Row\" >> beam.Map(\n",
    "#                 lambda row: di.parse_nut_row(row)\n",
    "#             )\n",
    "# #             | \"Print NUT\" >> beam.Map(print)            \n",
    "#         ) \n",
    "#         met_collection = (\n",
    "#             p\n",
    "#             | \"MET Dataset\" >> beam.Create(datasets.get(di.MET)[0:1])\n",
    "#             | \"Read MET CSV files\" >> ReadAllFromText(skip_header_lines=1)\n",
    "#             | \"Split MET CSV files\" >> beam.Map(di.read_csv)\n",
    "#             | \"MET Parse and To Row\" >> beam.Map(\n",
    "#                 lambda row: di.parse_met_row(row)\n",
    "#             )\n",
    "# #             | \"Print MET\" >> beam.Map(print)            \n",
    "#         )\n",
    "#         station_collection = (\n",
    "#             p\n",
    "#             | \"Station Dataset\" >> beam.Create(datasets.get(di.STATION)[0:1])\n",
    "#             | \"Read Station CSV files\" >> ReadAllFromText(skip_header_lines=1)\n",
    "#             | \"Split Station CSV files\" >> beam.Map(di.read_csv)\n",
    "#             | \"Station Parse and To Row\" >> beam.Map(\n",
    "#                 lambda row: di.parse_met_row(row)\n",
    "#             )\n",
    "# #             | \"Print MET\" >> beam.Map(print)            \n",
    "#         )        \n",
    "        result = p.run()\n",
    "        print(\"Done\")\n",
    "\n",
    "# run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineOptions()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataflow_endpoint DATAFLOW_ENDPOINT]\n",
      "                             [--project PROJECT] [--job_name JOB_NAME]\n",
      "                             [--staging_location STAGING_LOCATION]\n",
      "                             [--temp_location TEMP_LOCATION] [--region REGION]\n",
      "                             [--service_account_email SERVICE_ACCOUNT_EMAIL]\n",
      "                             [--no_auth]\n",
      "                             [--template_location TEMPLATE_LOCATION]\n",
      "                             [--label LABELS] [--update]\n",
      "                             [--transform_name_mapping TRANSFORM_NAME_MAPPING]\n",
      "                             [--enable_streaming_engine]\n",
      "                             [--dataflow_kms_key DATAFLOW_KMS_KEY]\n",
      "                             [--create_from_snapshot CREATE_FROM_SNAPSHOT]\n",
      "                             [--flexrs_goal {COST_OPTIMIZED,SPEED_OPTIMIZED}]\n",
      "                             [--dataflow_service_option DATAFLOW_SERVICE_OPTIONS]\n",
      "                             [--enable_hot_key_logging]\n",
      "                             [--enable_artifact_caching]\n",
      "                             [--impersonate_service_account IMPERSONATE_SERVICE_ACCOUNT]\n",
      "                             [--gcp_oauth_scope GCP_OAUTH_SCOPES]\n",
      "ipykernel_launcher.py: error: argument --flexrs_goal: invalid choice: 'c:\\\\Users\\\\alexa\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-24608gHPtqvFJIeB2.json' (choose from 'COST_OPTIMIZED', 'SPEED_OPTIMIZED')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:1858\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1857\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1858\u001b[0m     namespace, args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_known_args(args, namespace)\n\u001b[0;32m   1859\u001b[0m \u001b[39mexcept\u001b[39;00m ArgumentError:\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:2067\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2066\u001b[0m     \u001b[39m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[1;32m-> 2067\u001b[0m     start_index \u001b[39m=\u001b[39m consume_optional(start_index)\n\u001b[0;32m   2069\u001b[0m \u001b[39m# consume any positionals following the last Optional\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:2007\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[1;34m(start_index)\u001b[0m\n\u001b[0;32m   2006\u001b[0m \u001b[39mfor\u001b[39;00m action, args, option_string \u001b[39min\u001b[39;00m action_tuples:\n\u001b[1;32m-> 2007\u001b[0m     take_action(action, args, option_string)\n\u001b[0;32m   2008\u001b[0m \u001b[39mreturn\u001b[39;00m stop\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:1919\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.take_action\u001b[1;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[0;32m   1918\u001b[0m seen_actions\u001b[39m.\u001b[39madd(action)\n\u001b[1;32m-> 1919\u001b[0m argument_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_values(action, argument_strings)\n\u001b[0;32m   1921\u001b[0m \u001b[39m# error if this argument is not allowed with other previously\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[39m# seen arguments, assuming that actions that use the default\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[39m# value don't really count as \"present\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:2451\u001b[0m, in \u001b[0;36mArgumentParser._get_values\u001b[1;34m(self, action, arg_strings)\u001b[0m\n\u001b[0;32m   2450\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_value(action, arg_string)\n\u001b[1;32m-> 2451\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_value(action, value)\n\u001b[0;32m   2453\u001b[0m \u001b[39m# REMAINDER arguments convert all values, checking none\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:2507\u001b[0m, in \u001b[0;36mArgumentParser._check_value\u001b[1;34m(self, action, value)\u001b[0m\n\u001b[0;32m   2506\u001b[0m msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39minvalid choice: \u001b[39m\u001b[39m%(value)r\u001b[39;00m\u001b[39m (choose from \u001b[39m\u001b[39m%(choices)s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 2507\u001b[0m \u001b[39mraise\u001b[39;00m ArgumentError(action, msg \u001b[39m%\u001b[39m args)\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument --flexrs_goal: invalid choice: 'c:\\\\Users\\\\alexa\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-24608gHPtqvFJIeB2.json' (choose from 'COST_OPTIMIZED', 'SPEED_OPTIMIZED')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m\n\u001b[0;32m     35\u001b[0m options \u001b[39m=\u001b[39m PipelineOptions(sys\u001b[39m.\u001b[39margv[\u001b[39m1\u001b[39m:])\n\u001b[1;32m---> 36\u001b[0m run(options)\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(options)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(options)\n\u001b[1;32m---> 23\u001b[0m \u001b[39mwith\u001b[39;00m beam\u001b[39m.\u001b[39;49mPipeline(options\u001b[39m=\u001b[39;49moptions) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(options)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\apache_beam\\pipeline.py:198\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, runner, options, argv)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39m# Validate pipeline options\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m errors \u001b[39m=\u001b[39m PipelineOptionsValidator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options, runner)\u001b[39m.\u001b[39;49mvalidate()\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m errors:\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\apache_beam\\options\\pipeline_options_validator.py:146\u001b[0m, in \u001b[0;36mPipelineOptionsValidator.validate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mvalidate\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m \u001b[39mand\u001b[39;00m callable(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mvalidate\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m--> 146\u001b[0m     errors\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mview_as(\u001b[39mcls\u001b[39;49m)\u001b[39m.\u001b[39mvalidate(\u001b[39mself\u001b[39m))\n\u001b[0;32m    147\u001b[0m \u001b[39mreturn\u001b[39;00m errors\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\apache_beam\\options\\pipeline_options.py:400\u001b[0m, in \u001b[0;36mPipelineOptions.view_as\u001b[1;34m(self, cls)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39m\"\"\"Returns a view of current object as provided PipelineOption subclass.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \n\u001b[0;32m    381\u001b[0m \u001b[39mExample Usage::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m view \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flags)\n\u001b[0;32m    402\u001b[0m \u001b[39mfor\u001b[39;00m option_name \u001b[39min\u001b[39;00m view\u001b[39m.\u001b[39m_visible_option_list():\n\u001b[0;32m    403\u001b[0m   \u001b[39m# Initialize values of keys defined by a cls.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m   \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    408\u001b[0m   \u001b[39m# backed by the same list across multiple views, and that any overrides of\u001b[39;00m\n\u001b[0;32m    409\u001b[0m   \u001b[39m# pipeline options already stored in _all_options are preserved.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\apache_beam\\options\\pipeline_options.py:229\u001b[0m, in \u001b[0;36mPipelineOptions.__init__\u001b[1;34m(self, flags, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39m# The _visible_options attribute will contain options that were recognized\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[39m# by the parser.\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_visible_options, _ \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mparse_known_args(flags)\n\u001b[0;32m    231\u001b[0m \u001b[39m# self._all_options is initialized with overrides to flag values,\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39m# provided in kwargs, and will store key-value pairs for options recognized\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39m# by current PipelineOptions [sub]class and its views that may be created.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m# as each new views are created.\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39m# Users access this dictionary store via __getattr__ / __setattr__ methods.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:1861\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         err \u001b[39m=\u001b[39m _sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1861\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(\u001b[39mstr\u001b[39;49m(err))\n\u001b[0;32m   1862\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\apache_beam\\options\\pipeline_options.py:133\u001b[0m, in \u001b[0;36m_BeamArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m    132\u001b[0m   \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49merror(message)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:2582\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2581\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[1;32m-> 2582\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\argparse.py:2569\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2568\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m-> 2569\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2042\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2039\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2040\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2041\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2042\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2043\u001b[0m                                                      value))\n\u001b[0;32m   2044\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2045\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2046\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2048\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\IPython\\core\\ultratb.py:585\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    578\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \n\u001b[0;32m    580\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    584\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\IPython\\core\\ultratb.py:452\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    449\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    450\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    451\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 452\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    453\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[0;32m    454\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[0;32m    455\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    456\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    458\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\IPython\\core\\ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1117\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[1;32m-> 1118\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1119\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\IPython\\core\\ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1009\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1010\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1011\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1013\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\IPython\\core\\ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m    857\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    858\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    862\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m    863\u001b[0m ):\n\u001b[0;32m    864\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m    866\u001b[0m                                                            tb_offset)\n\u001b[0;32m    868\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\IPython\\core\\ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m    797\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m    798\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 799\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m    803\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\IPython\\core\\ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    848\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    849\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[0;32m    850\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[0;32m    851\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[0;32m    852\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[0;32m    853\u001b[0m )\n\u001b[1;32m--> 854\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\stack_data\\core.py:578\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    563\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[0;32m    564\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    569\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[0;32m    570\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[0;32m    580\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[0;32m    581\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[0;32m    582\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\stack_data\\utils.py:97\u001b[0m, in \u001b[0;36miter_stack\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[0;32m     96\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[1;32m---> 97\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[0;32m     98\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[0;32m     99\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\stack_data\\utils.py:90\u001b[0m, in \u001b[0;36mis_frame\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[0;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
      "File \u001b[1;32mc:\\Users\\alexa\\anaconda3\\envs\\gcloud\\lib\\site-packages\\stack_data\\utils.py:176\u001b[0m, in \u001b[0;36massert_\u001b[1;34m(condition, error)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    175\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[1;32m--> 176\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions, StandardOptions\n",
    " \n",
    "from datasource import ReadFromCsv\n",
    "# di = DataIngestions()\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "\n",
    "class NERRPipelineOptions(PipelineOptions):\n",
    "  @classmethod\n",
    "  def _add_argparse_args(cls, parser):\n",
    "    parser.add_argument(\"--station_files\", default=\"gs://environmental_data/landing_zone/cdmo/advanced_query_system/*/*stations*.csv\")\n",
    "    parser.add_argument(\"--nut_files\", default=\"gs://environmental_data/landing_zone/cdmo/advanced_query_system/*/*nut*.csv\")\n",
    "    parser.add_argument(\"--wq_files\", default=\"gs://environmental_data/landing_zone/cdmo/advanced_query_system/*/*wq*.csv\")\n",
    "    parser.add_argument(\"--met_files\", default=\"gs://environmental_data/landing_zone/cdmo/advanced_query_system/*/*met*.csv\")\n",
    "\n",
    "\n",
    "def run(options):\n",
    "    print(options)\n",
    "    \n",
    "    with beam.Pipeline(options=options) as p:\n",
    "        print(options)\n",
    "        data = (\n",
    "            p\n",
    "            | \"Read files\" >> ReadFromCsv(options.view_as(NERRPipelineOptions).station_files)\n",
    "    #         | \"NUT Parse and To Row\" >> beam.Map(\n",
    "    #             lambda row: di.parse_nut_row(row)\n",
    "    #         )        \n",
    "            | \"Print WQ\" >> beam.Map(print)\n",
    "        )\n",
    "\n",
    "import sys\n",
    "options = PipelineOptions(sys.argv[1:])\n",
    "run(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'NERRPipelineOptions' has no attribute 'nut_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m NERRPipelineOptions\u001b[39m.\u001b[39;49mnut_files\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'NERRPipelineOptions' has no attribute 'nut_files'"
     ]
    }
   ],
   "source": [
    "NERRPipelineOptions.nut_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ReadFromCsv' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0a3adba40c09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'ReadFromCsv' object is not iterable"
     ]
    }
   ],
   "source": [
    "[print(x) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a46f44ddd174a55782da539d3a1b617c81d01a6565ce83b6e1ffd93a2cd9ce77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
